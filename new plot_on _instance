import pandas as pd
import datetime as dt
import os
import xlsxwriter

pd.set_option('display.width', 1000, 'display.max_columns', 1000)

data = pd.read_csv(
    '/Users/Evanna.W/Desktop/2020-09-25/130019805858-aws-billing-detailed-line-items-with-resources-and-tags-2020-09.csv.zip',
    compression='zip')
data.columns = [x.lower().replace(':', '_') for x in data.columns]

data = data.loc[(data['user_mapid'] == 10147.0) | (data['user_project'].str.lower() == 'cva')]
data = data[data['recordtype'] == 'LineItem']
data = data[~(data['blendedcost'] == 0.0)]
# data.to_pickle('../routines/raw_2020_09.p')

# data = pd.read_pickle('/Users/Evanna.W/Desktop/2020-09-25/routines/raw_2020_09.p')
start_time = dt.datetime.now()


def process_csv(file):
    print(f'-   processing:   {file}  |  {dt.datetime.now() - start_time}')
    data = pd.read_csv(f'{csv_dir}/{file}', compression='zip')
    data.columns = [x.lower().replace(':', '_') for x in data.columns]
    data = data.loc[(data['user_mapid'] == 10147.0) | (data['user_project'].str.lower() == 'cva')]
    data = data[data['recordtype'] == 'LineItem']
    data = data[~(data['blendedcost'] == 0.0)]
    data = data['productname usageenddate user_environment blendedcost resourceid'.split(' ')]
    data = data.rename(
        columns={'productname': 'product_name', 'usageenddate': 'end_date', 'resourceid': 'resource',
                 'user_environment': 'env',
                 'blendedcost': 'cost'})

    map_env = {'dev_test_5': 'dev-5',
               'dev_test_1': 'dev-1',
               'dev_test_2': 'dev-2',
               'dev_test_3': 'dev-3',
               'dev_test_4': 'dev-4',
               'dev_test_6': 'dev-6',
               'dev_test_7': 'dev-7',
               'dev_ci': 'dev-8',
               'uat_b': 'uat-b',
               'prod_b': 'prod-b',
               }

    map_product = {'Amazon Elastic Compute Cloud': 'EC2',
                   'Amazon Simple Storage Service': 'S3',
                   'Elastic Load Balancing': 'LoadBalance'
                   }

    data.env = data.env.apply(lambda x: map_env.get(x, x))
    data.product_name = data.product_name.apply(lambda x: map_product.get(x, x))

    data.end_date = pd.to_datetime(data.end_date, format='%Y-%m-%d %H:%M:%S', errors='coerce')
    data.set_index('end_date', inplace=True)
    return data


csv_dir = '/Users/Evanna.W/Desktop/2020-09-25'
for _, _, files in os.walk(csv_dir):
    pass

files = [f for f in files if '.csv.zip' in f]
files = sorted(files)[-3:]
files = [process_csv(f) for f in files]

data = pd.concat(files, sort=False)
data = data.groupby([pd.Grouper(freq='D'), 'env', 'product_name']).sum()
data = data.unstack(1)
data = data.xs('EC2', level='product_name')
data.columns = data.columns.droplevel()
data['total'] = data.sum(axis=1)
# mt.barh(data, data['total'])

data.sort_index(ascending=False, inplace=True)

total_value = data['total']
max_value = data['total'].max()
total_value = total_value.map(lambda x: x / max_value)
data['percent'] = total_value
writer = pd.ExcelWriter('daily_cva.xlsx')
data.to_excel(writer, 'Daily')

length = str(total_value.size + 1)
workbook = writer.book
worksheet = writer.sheets['Daily']
worksheet.conditional_format('$X$2:$X$'+length, {'type':'data_bar'})

chart1 = workbook.add_chart({'type': 'bar'})
chart1.add_series({
    'name': '=Daily!$X$1',
    'categories': '=Daily!$A$2:$A$' + length,
    'values': '=Daily!$X$2:$X$' + length,
})

chart1.set_title({'name': 'Results of data analysis'})
chart1.set_x_axis({'name': 'Test number'})
chart1.set_y_axis({'name': 'Data length (mm)'})
chart1.set_style(11)
worksheet.insert_chart('AA7', chart1)
workbook.close()
